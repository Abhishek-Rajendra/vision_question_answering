base:
  device: 1     # set to -1 if you don't have a GPU
  
data:
  dataset_folder: dataset
  images_folder: images
  all_qa_pairs_file: all_qa_pairs.txt
  train_dataset: data_train.csv
  eval_dataset: data_eval.csv
  question_col: question
  image_col: image_id
  answer_col: answer
  answer_space: answer_space.txt

tokenizer:
  padding: longest
  max_length: 24
  truncation: True
  return_token_type_ids: True
  return_attention_mask: True

model:
  name: roberta-deit # Custom name for the multimodal model
  text_encoder: roberta-base # Valid transformer model for text encoding from HuggingFace eg: roberta-base, bert-base-uncased, albert-base-v2
  image_encoder: facebook/deit-base-distilled-patch16-224 # Valid transformer model for image encoding from HuggingFace eg: google/vit-base-patch16-224-in21k, oogle/vit-base-patch16-224-in21k, microsoft/beit-base-patch16-224-pt22k-ft22k 
  intermediate_dims: 512
  dropout: 0.5

trainer:
  devices: [0,1]  # set to -1 if you don't have a GPU
  max_epochs: 200
  log_every_n_steps: 100
  precision: 32    # set to 16 for mixed precision training

training:
  checkpoint: checkpoints
  early_stop_patience: 50
  save_top_k: 3
  lr: 5.0e-5
  batch_size: 32
  num_workers: 8

metrics:
  metrics_folder: metrics

inference:
  checkpoint: checkpoint-epoch=23